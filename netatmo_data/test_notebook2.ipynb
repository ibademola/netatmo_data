{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import folium\n",
    "import pandas as pd\n",
    "import csv\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the path to your project\n",
    "sys.path.append('C:/Users/herde/OneDrive - The Hong Kong Polytechnic University/PhD/PhD Research/Research Objectives/Objective 4/Py_Code/netatmo_data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_id = \"66c36f135947dd83b00887bb\"\n",
    "client_secret = \"xqM6Cd5MSMhlCd87XKM5Wn87P\"\n",
    "refresh_token = \"6639b0eb66bcd29b9809e8f4|9386ef9ff8b36f95ca546bc002654578\"\n",
    "lat_ne = '-26.083963'\n",
    "lon_ne = '28.14711'\n",
    "lat_sw = '-26.263'\n",
    "lon_sw = '27.92019'\n",
    "csv_file = \"JB.csv\"\n",
    "start_date_stamp = '20150101'\n",
    "start_time_stamp = '0000'\n",
    "end_date_stamp = '20201231'\n",
    "end_time_stamp = '2300'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_fetcher import get_access_token, fetch_station_ids, fetch_temperature_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = get_access_token(client_id, client_secret, refresh_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6639b0eb66bcd29b9809e8f4|4b94a264b0d445f71c5441cdb9c2e640\n"
     ]
    }
   ],
   "source": [
    "print(access_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 400 {\"error\":\"invalid_grant\"}\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "fetch_temperature_data() missing 2 required positional arguments: 'end_date_stamp' and 'end_time_stamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m access_token \u001b[38;5;241m=\u001b[39m get_access_token(client_id, client_secret, refresh_token)\n\u001b[1;32m----> 2\u001b[0m \u001b[43mfetch_temperature_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccess_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcsv_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_date_stamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time_stamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date_stamp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_time_stamp\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mTypeError\u001b[0m: fetch_temperature_data() missing 2 required positional arguments: 'end_date_stamp' and 'end_time_stamp'"
     ]
    }
   ],
   "source": [
    "access_token = get_access_token(client_id, client_secret, refresh_token)\n",
    "fetch_temperature_data(access_token, csv_file, start_date_stamp, start_time_stamp, end_date_stamp, end_time_stamp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_device_and_module_ids_from_csv(csv_file):\n",
    "    device_module_ids = []\n",
    "    with open(csv_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.reader(file)\n",
    "        next(reader)  # Skip the header row\n",
    "        for row in reader:\n",
    "            device_id = row[0]\n",
    "            module_id = row[1].strip(\"[]'\")  # Remove square brackets and single quotes\n",
    "            device_module_ids.append((device_id, module_id))\n",
    "    return device_module_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_module_ids = load_device_and_module_ids_from_csv(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_measurements(access_token, device_id, module_id, scale, types, date_begin, date_end, limit=1024):\n",
    "    url = \"https://api.netatmo.net/api/getmeasure\"\n",
    "    \n",
    "    params = {\n",
    "        'access_token': access_token,\n",
    "        'device_id': device_id,\n",
    "        'module_id': module_id,\n",
    "        'scale': scale,\n",
    "        'type': types,\n",
    "        'date_begin': date_begin,\n",
    "        'date_end': date_end,\n",
    "        'limit': limit\n",
    "    }\n",
    "\n",
    "    response = requests.get(url, params=params)\n",
    "\n",
    "    if response.status_code == 200:\n",
    "        return response.json()\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_measurements_to_csv(measurements, device_id, module_id):\n",
    "    # Remove \":\" from device and module IDs for filename\n",
    "    device_id_filename = device_id.replace(\":\", \"\")\n",
    "    module_id_filename = module_id.replace(\":\", \"\")\n",
    "    \n",
    "    filename = f'{device_id_filename}_{module_id_filename}_measurements.csv'\n",
    "    \n",
    "    with open(filename, 'a', newline='') as csvfile:\n",
    "        fieldnames = ['acquisition_time', 'temperature', 'humidity', 'pressure']\n",
    "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "        # Skip writing header if file is not empty\n",
    "        if csvfile.tell() == 0:\n",
    "            writer.writeheader()\n",
    "\n",
    "        acquisition_time = measurements['body'][0]['beg_time']\n",
    "        step_time = 86400\n",
    "        # step_time = measurements['body'][0]['step_time']\n",
    "        for entry in measurements['body']:\n",
    "            for value in entry['value']:\n",
    "                row = {\n",
    "                    'acquisition_time': datetime.utcfromtimestamp(acquisition_time).strftime('%Y%m%d%H%M'),\n",
    "                    'temperature': value[0],\n",
    "                    'humidity': value[1],\n",
    "                    'pressure': value[2]\n",
    "                }\n",
    "                writer.writerow(row)\n",
    "                acquisition_time += step_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_historical_measurements_batch(access_token, device_id, module_id, scale, types, date_begin, date_end, limit=1024):\n",
    "    all_measurements = []\n",
    "\n",
    "    while date_begin < date_end:\n",
    "        measurements = get_historical_measurements(access_token, device_id, module_id, scale, types, date_begin, date_end, limit)\n",
    "        if measurements is None or \"body\" not in measurements or not measurements[\"body\"]:\n",
    "            # No more data available or an error occurred, stop the loop\n",
    "            break\n",
    "\n",
    "        # Extract the last timestamp from the received data\n",
    "        last_timestamp = measurements[\"body\"][-1][\"beg_time\"]\n",
    "        \n",
    "        # Append the measurements to the list\n",
    "        all_measurements.extend(measurements[\"body\"])\n",
    "\n",
    "        # Update date_begin to fetch the next batch of data\n",
    "        date_begin = last_timestamp + 86400\n",
    "        # date_begin = last_timestamp + measurements[\"body\"][-1][\"step_time\"]\n",
    "\n",
    "        # Save measurements to CSV file\n",
    "        save_measurements_to_csv(measurements, device_id, module_id)\n",
    "\n",
    "        # Introduce a delay to avoid hitting rate limits\n",
    "        time.sleep(1)\n",
    "\n",
    "    return all_measurements\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_unix_timestamp(date_string, time_string):\n",
    "    try:\n",
    "        # Parse the date and time strings\n",
    "        date_obj = datetime.strptime(date_string, '%Y%m%d')\n",
    "        time_obj = datetime.strptime(time_string, '%H%M')\n",
    "        \n",
    "        # Combine date and time\n",
    "        datetime_obj = datetime(date_obj.year, date_obj.month, date_obj.day, time_obj.hour, time_obj.minute)\n",
    "        \n",
    "        # Convert to UNIX timestamp\n",
    "        timestamp = int(datetime_obj.timestamp())\n",
    "        return timestamp\n",
    "    except ValueError:\n",
    "        print(\"Error: Invalid input format. Please provide date in 'yyyymmdd' and time in 'hhmm' format.\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "access_token = get_access_token(client_id, client_secret, refresh_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------data for ('70:ee:50:06:8f:36', '02:00:00:06:9d:c0') completely downloaded----------\n",
      "--------data for ('70:ee:50:1b:2a:2a', '02:00:00:1b:0c:16') completely downloaded----------\n",
      "--------data for ('70:ee:50:17:d3:e0', '02:00:00:17:5e:00') completely downloaded----------\n",
      "--------data for ('70:ee:50:6b:6c:26', '02:00:00:6b:2f:f6') completely downloaded----------\n",
      "--------data for ('70:ee:50:6b:73:18', '02:00:00:6b:35:5e') completely downloaded----------\n",
      "--------data for ('70:ee:50:64:02:5a', '02:00:00:63:fc:0c') completely downloaded----------\n",
      "--------data for ('70:ee:50:7f:9e:64', '02:00:00:7f:8d:32') completely downloaded----------\n",
      "--------data for ('70:ee:50:83:f3:fc', '02:00:00:83:f5:42') completely downloaded----------\n",
      "--------data for ('70:ee:50:05:e1:e6', '02:00:00:12:f7:8e') completely downloaded----------\n",
      "--------data for ('70:ee:50:65:11:fa', '02:00:00:65:31:0c') completely downloaded----------\n",
      "--------data for ('70:ee:50:7a:70:f0', '02:00:00:7a:b0:02') completely downloaded----------\n",
      "--------data for ('70:ee:50:13:55:0e', '02:00:00:13:84:3e') completely downloaded----------\n",
      "--------data for ('70:ee:50:01:6b:5e', '02:00:00:01:6c:74') completely downloaded----------\n",
      "--------data for ('70:ee:50:84:af:86', '02:00:00:90:77:b2') completely downloaded----------\n",
      "--------data for ('70:ee:50:13:1f:88', '02:00:00:12:ff:be') completely downloaded----------\n",
      "--------data for ('70:ee:50:13:24:5e', '02:00:00:12:f5:c6') completely downloaded----------\n",
      "--------data for ('70:ee:50:13:27:92', '02:00:00:12:fd:4c') completely downloaded----------\n",
      "--------data for ('70:ee:50:00:2a:96', '02:00:00:00:2a:e8') completely downloaded----------\n",
      "--------data for ('70:ee:50:83:e2:5e', '02:00:00:83:f5:ea') completely downloaded----------\n",
      "--------data for ('70:ee:50:74:51:fa', '02:00:00:74:56:f4') completely downloaded----------\n",
      "--------data for ('70:ee:50:6b:68:d2', '02:00:00:6b:38:0e') completely downloaded----------\n",
      "--------data for ('70:ee:50:05:e0:82', '02:00:00:05:3f:c8') completely downloaded----------\n",
      "--------data for ('70:ee:50:1e:20:06', '02:00:00:1e:04:78') completely downloaded----------\n",
      "--------data for ('70:ee:50:6b:67:e6', '02:00:00:6b:39:a4') completely downloaded----------\n",
      "--------data for ('70:ee:50:64:f5:26', '02:00:00:65:25:28') completely downloaded----------\n",
      "--------data for ('70:ee:50:74:20:a4', '02:00:00:74:26:58') completely downloaded----------\n",
      "--------data for ('70:ee:50:22:e6:74', '02:00:00:22:d5:02') completely downloaded----------\n",
      "--------data for ('70:ee:50:37:10:9c', '02:00:00:3a:3b:e8') completely downloaded----------\n",
      "--------data for ('70:ee:50:83:e9:74', '02:00:00:84:08:58') completely downloaded----------\n",
      "--------data for ('70:ee:50:02:67:9a', '02:00:00:02:67:b0') completely downloaded----------\n",
      "--------data for ('70:ee:50:06:ae:be', '02:00:00:05:cd:bc') completely downloaded----------\n",
      "--------data for ('70:ee:50:13:27:56', '02:00:00:12:f6:d4') completely downloaded----------\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'start_time' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     measurements \u001b[38;5;241m=\u001b[39m get_historical_measurements_batch(access_token, device_id, module_id, scale, types, date_begin, date_end, limit)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m--------data for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice_id,\u001b[38;5;250m \u001b[39mmodule_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m completely downloaded----------\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 12\u001b[0m processing_time_seconds \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[43mstart_time\u001b[49m\n\u001b[0;32m     13\u001b[0m processing_time_formatted \u001b[38;5;241m=\u001b[39m format_time(processing_time_seconds)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData for all devices downloaded successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprocessing_time_formatted\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'start_time' is not defined"
     ]
    }
   ],
   "source": [
    "for device_id, module_id in device_module_ids:\n",
    "    scale = \"1day\"  # Change according to your requirement\n",
    "    types = \"Temperature,Humidity,Pressure\"  # Add or remove types as needed\n",
    "    date_begin = convert_to_unix_timestamp(start_date_stamp, start_time_stamp)  # Start timestamp\n",
    "    date_end = convert_to_unix_timestamp(end_date_stamp, end_time_stamp)  # End timestamp, set to \"last\" to retrieve only the last measurement\n",
    "    limit = 1024  # Default limit\n",
    "\n",
    "    # Fetch historical measurements for the current device ID and module ID pair\n",
    "    measurements = get_historical_measurements_batch(access_token, device_id, module_id, scale, types, date_begin, date_end, limit)\n",
    "    print(f'--------data for {device_id, module_id} completely downloaded----------')\n",
    "\n",
    "processing_time_seconds = time.time() - start_time\n",
    "processing_time_formatted = format_time(processing_time_seconds)\n",
    "\n",
    "print(\"Data for all devices downloaded successfully.\", f\"Processing time: {processing_time_formatted}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
